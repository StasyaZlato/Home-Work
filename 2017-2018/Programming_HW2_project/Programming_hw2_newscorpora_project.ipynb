{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# импортируем все, что нужно\n",
    "\n",
    "import urllib.request # для работы с сайтами\n",
    "import re # регулярки\n",
    "import os # ходить по папкам\n",
    "import csv # табличка\n",
    "import time # чтобы поставить перерывы между обращениями к серверу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем папки \n",
    "\n",
    "def make_folders():\n",
    "    directory = os.path.join('.', 'Yoshkar-Ola')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory) # создаем корневую директорию\n",
    "    directories = [directory + '\\\\plain', directory + '\\\\mystem-xml', directory + '\\\\mystem-plain']\n",
    "    for dirs in directories: # создаем каталоги для текстов   \n",
    "        if not os.path.exists(dirs):\n",
    "            for year in range(2014, 2018): # папки по годам\n",
    "                folder_year = dirs + '\\\\' + str(year)\n",
    "                if not os.path.exists(folder_year):\n",
    "                    os.makedirs(folder_year)\n",
    "                for month in range(1,13): # папки по месяцам (второй аргумент range - не входит в промежуток)\n",
    "                    folder_month = folder_year + '\\\\' + str(month)\n",
    "                    if not os.path.exists(folder_month):\n",
    "                        os.makedirs(folder_month)\n",
    "    print('Директории созданы.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция, скачивающая любую страницу\n",
    "\n",
    "def download(pageUrl):\n",
    "    try:\n",
    "        page = urllib.request.urlopen(pageUrl) # берем страницу\n",
    "        html = page.read().decode('utf-8') # достаем html\n",
    "        return html \n",
    "    except:\n",
    "        print('Error at ', pageUrl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция, удаляющая из строки html символы\n",
    "\n",
    "def del_html(a):\n",
    "    import html\n",
    "    a = html.unescape(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ф-я, ищущая на странице новостей ссылки на отдельные статьи\n",
    "\n",
    "def find_news_URL(url_main):\n",
    "    references = []\n",
    "    content_main = download(url_main) # скачиваем страницу раздела\n",
    "    reg_ref = re.compile('<h2 class=\"entry-title\"><a href=\"(.*?)\" rel=\"bookmark\">', re.DOTALL) # регулярка для ссылки\n",
    "    ref = re.findall(reg_ref, content_main) # ищем\n",
    "    for r in ref:\n",
    "        ref1 = re.sub('<h2.*?><a href=\"', '', r) # убираем теги из найденного\n",
    "        reference = re.sub('\" rel=\"bookmark\">', '', ref1)\n",
    "        references.append(reference) # кидаем в итоговый массив\n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ф-я, ищущая номер последней страницы архива новостей \n",
    "# на каждой странице отображаются номер первой, предыдущей, следущей и последней страниц\n",
    "\n",
    "def last_page():\n",
    "    url = 'https://gg12.ru/category/novosti/'\n",
    "    html = download(url)\n",
    "    reg_pages = re.compile('<a class=\\'page-numbers\\'.*?>(\\d+)</a>', re.DOTALL) # ищем все видные на странице номера страниц\n",
    "    pages = re.findall(reg_pages, html)\n",
    "    nums = []\n",
    "    for i in pages:\n",
    "        i1 = re.sub(reg_pages, '\\1', i) # вычленяем только число между тегами\n",
    "        nums.append(int(i1))\n",
    "    return max(nums) # страница с максимальным номером - и есть последняя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mystem принимает только файлы с названием на латинице. Мне лень переделывать красивую функцию, \n",
    "# называющие файлы по названию статьи. Легче написать еще одну для транслитерации xD\n",
    "\n",
    "def transliter(string):\n",
    "    dic_alph_cyr_lat = {'а':'a',\n",
    "                       'б':'b',\n",
    "                       'в':'v',\n",
    "                       'г':'g',\n",
    "                       'д':'d',\n",
    "                       'е':'e',\n",
    "                       'ё':'e',\n",
    "                       'ж':'zh',\n",
    "                       'з':'z',\n",
    "                       'и':'i',\n",
    "                       'й':'j',\n",
    "                       'к':'k',\n",
    "                       'л':'l',\n",
    "                       'м':'m',\n",
    "                       'н':'n',\n",
    "                       'о':'o',\n",
    "                       'п':'p',\n",
    "                       'р':'r',\n",
    "                       'с':'s',\n",
    "                       'т':'t',\n",
    "                       'у':'u',\n",
    "                       'ф':'f',\n",
    "                       'х':'h',\n",
    "                       'ц':'ts',\n",
    "                       'ч':'ch',\n",
    "                       'ш':'sh',\n",
    "                       'щ':'sch',\n",
    "                       'ъ':'',\n",
    "                       'ы':'y',\n",
    "                       'ь':'',\n",
    "                       'э':'e',\n",
    "                       'ю':'yu',\n",
    "                       'я':'ya',\n",
    "                       ' ':'_'} # словарь кириллица VS латиница\n",
    "    string = string.lower() # Приведем строку к нижнему регистру, потому что иначе аббревиатуры будут выглядеть некрасиво\n",
    "    for cyrillic, latin in dic_alph_cyr_lat.items():\n",
    "        string = string.replace(cyrillic, latin)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ф-я, проходящая по всем папкам директории и достающая оттуда все файлы\n",
    "\n",
    "def list_files(path):\n",
    "    files_list = []\n",
    "    for d, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            path_f = os.path.join(d, f)\n",
    "            files_list.append(path_f)\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ф-я, определяющая будущее название файла и путь к нему\n",
    "\n",
    "def path_html(url, html):\n",
    "    path_base = os.path.join('.', 'Yoshkar-Ola\\\\plain')\n",
    "    metadata = meta(url, html) # ищем данные для определения пути\n",
    "    date = metadata['created']\n",
    "    date_f = date.split('.') \n",
    "    date_year = date_f[2] # год\n",
    "    date_month = int(date_f[1]) # месяц. int - чтобы убрать 0 в начале (напр. 04)\n",
    "    prob_illegal_title = transliter(metadata['header']) \n",
    "    illegal = re.compile('[\\?#%&\\*\\.,\\|:\\\"«»<>/№;!–-—]') # убираем все \"незаконные\" символы \n",
    "    title = re.sub(illegal, '', prob_illegal_title)\n",
    "    if title.count('\\\\') > 0: # почему-то регуляркой backslash не захотел убираться, прописываем отдельно\n",
    "        title = title.replace('\\\\', '')\n",
    "    path = path_base + '\\\\' + date_year + '\\\\' + str(date_month) + '\\\\' + title + '.txt'\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ф-я, вытаскивающая из html инфу для начала файла\n",
    "\n",
    "\n",
    "def inf(file, URL, html):\n",
    "    metadata = meta(URL, html)\n",
    "    with open(file, 'a', encoding = 'utf-8') as f:\n",
    "        f.write('@au ' + metadata['author'] + '\\n')\n",
    "        f.write('@ti ' + metadata['header'] + '\\n')\n",
    "        f.write('@da ' + metadata['created'] + '\\n')\n",
    "        f.write('@topic ' + metadata['topic'] + '\\n')\n",
    "        f.write('@url ' + URL + '\\n' + '\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ф-я, очищающая html от тегов и иже с ними\n",
    "\n",
    "def clean(text):\n",
    "    # убираем все под тегом <head>\n",
    "    reg_head = re.compile('<head>.*?</head>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_head, '', text)\n",
    "    # убираем все ссылки\n",
    "    reg_ref = re.compile('<a .*?>.*?</a>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_ref, '', clean_html)\n",
    "    # убираем \"Читайте также\"\n",
    "    reg_related = re.compile('<div class=\"related-content-wrapper\">.*?</div><!-- related-content-wrapper -->', re.DOTALL)\n",
    "    clean_html = re.sub(reg_related, '', clean_html)\n",
    "    # убираем комменты\n",
    "    reg_com = re.compile('<!--.*?-->', re.DOTALL)\n",
    "    clean_html = re.sub(reg_com, '', clean_html)\n",
    "    # убираем возрастное ограничение\n",
    "    reg_age = re.compile('<section id=\"text-8\" class=\"widget widget_text\">.*?<div class=\"textwidget\">.*?</div>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_age, '', clean_html)\n",
    "    # убираем сегодняшнюю дату\n",
    "    reg_tdate = re.compile('<div class=\"date-section\">.*?<\\/div>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_tdate, '', clean_html)\n",
    "    # убираем все скрипты\n",
    "    reg_script = re.compile('<script.*?>.*?</script>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_script, '', clean_html)\n",
    "    # убираем заголовки - они есть в шапке\n",
    "    reg_titles = re.compile('<h(1|2|3|4).*?>.*?</h(1|2|3|4)>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_titles, '', clean_html)\n",
    "    # убираем строчку поделиться - иначе она уходить не хочет\n",
    "    reg_share = re.compile('<p class=\"screen-reader-text juiz_sps_maybe_hidden_text\">.*?</p>', re.DOTALL)\n",
    "    clean_html = re.sub(reg_share, '', clean_html)\n",
    "    # наконец, убираем непосредственно все теги\n",
    "    reg_tags = re.compile('<.*?>', re.DOTALL)\n",
    "    html_clean = re.sub(reg_tags, '', clean_html)\n",
    "    # убираем встречающиеся в html символы |\n",
    "    html_clean = re.sub('\\|', '', html_clean)\n",
    "    # убираем лишние табуляции и пустые строки\n",
    "    hc = re.sub('\\t{2,}', '', html_clean)\n",
    "    hc = re.sub('\\s{2,}', '\\n', hc)\n",
    "    # если не убирать тег span, то находится много лишнего до и после текста. Если убирать - часть\n",
    "    # статей, в которых контент тоже оформлен в этот тег, остается пустой. Поэтому просто обрезаем \n",
    "    # всю оставшуюся ерунду\n",
    "    reg_content = re.compile('Найти:(.*?)Просмотров:.*?gg12.ru', re.DOTALL)\n",
    "    content_1 = re.search(reg_content, hc)\n",
    "    content = content_1.group(1)\n",
    "    hc = re.sub(reg_content, content, hc)\n",
    "    # обрезаем пробелообразные символы в начале и в конце\n",
    "    hc = hc.strip()\n",
    "    # убираем html-символы \n",
    "    hc = del_html(hc)\n",
    "    return hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ф-я, инвертирующая словарь\n",
    "\n",
    "def invert_dic(d):\n",
    "    inverted_dic = {value:key for key, value in d.items()}\n",
    "    return inverted_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ф-я, вытаскивающая метаданные из html\n",
    "\n",
    "def meta(URL, html):\n",
    "    html = del_html(html)\n",
    "    reg_author = re.compile('<div class=\"entry-meta\">(.*?)<span class=\"author vcard\">(.*?)</a>', re.DOTALL) # регулярка для автора\n",
    "    reg_title = re.compile('<h1 class=\"entry-title\">(.*?)</h1>', re.DOTALL) # регулярка для заголовка\n",
    "    reg_created = re.compile('<div class=\"entry-meta\">.*?<time.*?>(.*?)</time>', re.DOTALL) # регулярка для даты\n",
    "    reg_topic = re.compile('<span class=\"tags-links\">Tagged(.*?)</span>', re.DOTALL) # регулярка для категории\n",
    "    author1 = re.search(reg_author, html) # ищем рег1 - автора\n",
    "    if author1 != None:\n",
    "        author2 = author1.group(2)\n",
    "        author = re.sub('<.*?>', '', author2) # т.к. регулярка неаккуратная (иначе была бы слишком длинной), приходится еще избавляться от тегов\n",
    "    else:\n",
    "        author = ''\n",
    "    title = re.search(reg_title, html).group(1) # ищем рег2 - заголовки\n",
    "    created = re.search(reg_created, html) # ищем рег3 - дата\n",
    "    created1 = created.group(1)\n",
    "    topic1 = re.search(reg_topic, html)\n",
    "    if topic1 != None:\n",
    "        topic2 = topic1.group(1) # ищем рег4 - категории\n",
    "        topic = re.sub('<.*?>', '', topic2) # регулярка опять корявая, поэтому снова убираем теги\n",
    "    else:\n",
    "        topic = ''\n",
    "    dic_meta = {'author': author, 'sex': '', 'birthday': '', 'header': title, 'created': created1, 'sphere': 'публицистика', 'genre_fi': '', 'type': '', 'topic': topic, 'chronotop': '', 'style': 'нейтральный', 'audience_age': 'н-возраст', 'audience_level': 'н-уровень', 'audience_size': 'городская', 'source': URL, 'publication': 'Йошкар-Ола', 'publisher': '', 'publ_year': created1[-4:], 'medium': 'газета', 'country': 'Россия', 'region': 'Марий-Эл', 'language': 'ru'} # создаем словарь\n",
    "    return dic_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ф-я, создающая csv таблицу\n",
    "\n",
    "def csv_meta_base():\n",
    "    file = os.path.join('.', 'Yoshkar-Ola\\\\metadata.csv')\n",
    "    # заливаем все переменные в список\n",
    "    data = [['path', 'author', 'sex', 'birthday', 'header', 'created', 'sphere', 'genre_fi', 'type', 'topic', 'chronotop', 'style', 'audience_age', 'audience_level', 'audience_size', 'source', 'publication', 'publisher', 'publ_year', 'medium', 'country', 'region', 'language']]\n",
    "    # воспользуемся модулем csv\n",
    "    if not os.path.exists(file):\n",
    "        with open(file, 'w', newline = '') as f:\n",
    "            writer = csv.writer(f, delimiter = '\\t')\n",
    "            writer.writerows(data)\n",
    "        print('Шаблон таблицы csv создан.')\n",
    "    else:\n",
    "        print('Таблица с метаданными уже существует.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ф-я, заполняющая строки таблицы\n",
    "\n",
    "def meta_csv(ref, html, file): # ref - ссылка, html - текст html, file - путь к файлу. \n",
    "    # Можно было обойтись ссылкой, но тогда пришлось бы лишний раз обращаться к серверу для скачки материалов\n",
    "    meta_csv = []\n",
    "    metadata = meta(ref, html) # берем метаданные конкретного файла\n",
    "    meta_list = [file] # в метаданных изначально нет сочетания путь:значение пути, его заливаем в нужный список отдельно\n",
    "    inv_meta = invert_dic(metadata)\n",
    "    meta_list.extend(inv_meta.keys())\n",
    "    meta_csv.append(meta_list)\n",
    "    with open(os.path.join('.', 'Yoshkar-Ola\\\\metadata.csv'), 'a', newline = '') as f:\n",
    "        writer = csv.writer(f, delimiter = '\\t')\n",
    "        writer.writerows(meta_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ф-я, заливающая обработанные html в соотв. папки директории plain\n",
    "\n",
    "def plain():\n",
    "    url = 'https://gg12.ru/category/novosti/page'\n",
    "    last = last_page()\n",
    "    # i - по количеству страниц в архиве\n",
    "    for i in range(1, last+1):\n",
    "    #for i in [1,2]:\n",
    "        # url каждой страницы вполне ищется при добавлении \"page№\" или \"page/№\" в конце ссылки \n",
    "        url1 = url + str(i)\n",
    "        refs = find_news_URL(url1)\n",
    "        # идем по ссылкам на странице\n",
    "        for ref in refs:\n",
    "            try:\n",
    "                html = download(ref) # скачиваем\n",
    "                file = path_html(ref, html) # даем файлу имя\n",
    "                    # проверяем наличие файла в директории\n",
    "                if not os.path.exists(file):\n",
    "                    inf (file, ref, html)\n",
    "                    html_clean = clean(html) # чистим\n",
    "                    with open(file, 'a', encoding = 'utf-8') as f:\n",
    "                        f.write(html_clean)\n",
    "                        f.close()\n",
    "                    meta_csv(ref, html, file)\n",
    "                    # делаем паузу между запросами\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print('Error at ', ref)\n",
    "    print('Выкачка файлов в папку plain завершена. Таблица csv заполнена.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# После первой обработки всего массива файлов в mystem оказалось, что часть файлов выпадают в ошибку. \n",
    "# У этих файлов в названии оказались несколько пропущенных мной в программе создания пути к файлу \"нелегальных\" (для mystem) символов. \n",
    "# Я исправила ошибку в теле кода, но выкачивать все 2000+ файлов с сайта заново кажется не очень оправданным. Поэтому делаем ф-ю, \n",
    "# переименовывающую файлы в директории, если в них оказались символы, не принимаемые mystem-ом.\n",
    "\n",
    "def rename_file(directory):\n",
    "    files = list_files(directory)\n",
    "    regex= re.compile('[\\?#%&\\*,\\|:\\\"«»<>/№;!–-—`]') # еще раз пропишу все символы\n",
    "    for f in files:\n",
    "        list_n = f.split('\\\\')\n",
    "        name = list_n[-1]\n",
    "        if re.search(regex, name) != None: \n",
    "            new_name = re.sub(regex, '', name)\n",
    "            new_name = re.sub('__', '_', new_name)\n",
    "            list_n1 = list_n[:-1]\n",
    "            list_n1.append(new_name)\n",
    "            new_name_path = '\\\\'.join(list_n1)\n",
    "            os.rename(f, new_name_path)\n",
    "    print('Файлы в директории переименованы.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Убираем строки с метаданными из файлов mystem папок\n",
    "\n",
    "def cut_meta(path):\n",
    "    with open(path, 'r', encoding = 'utf-8') as f: \n",
    "        text = f.readlines()\n",
    "        text_wm_l = text[6:]\n",
    "        text_wm = ''.join(text_wm_l)\n",
    "        f.close()\n",
    "    with open(path, 'w', encoding = 'utf-8') as f:\n",
    "        f.write(text_wm)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Размечаем майстемом в формате plain text\n",
    "\n",
    "def mystem_plain():\n",
    "    path_base = os.path.join('.', 'Yoshkar-Ola\\\\plain')\n",
    "    files = list_files(path_base) # берем все файлы директории plain\n",
    "    #создаем на всякий случай файл, в который уйдут названия всех файлов с ошибками\n",
    "    with open(os.path.join('.', 'Yoshkar-Ola\\\\errors_mystem.txt'), 'a', encoding='utf-8') as n: \n",
    "        n.write('Ф-я mystem_plain(). Ошибки при обработке следующих файлов: ' + '\\n')\n",
    "        n.close()\n",
    "    for f in files:\n",
    "        try:\n",
    "            f_path_new = f.replace('plain', 'mystem-plain')\n",
    "            if not os.path.exists(f_path_new): # обрабатываем все файлы mystem, если еще нет\n",
    "                mystem_path = os.path.join('.', 'mystem.exe')\n",
    "                os.system(mystem_path + \" -cid \" + f + ' ' + f_path_new)\n",
    "                cut_meta(f_path_new)\n",
    "        except FileNotFoundError: # собственно единственная ошибка, которая возникала (кажется) из-за имени файла\n",
    "            print('Ошибка при обработке файла ' + f)\n",
    "            with open(os.path.join('.', 'Yoshkar-Ola\\\\errors_mystem.txt'), 'a', encoding='utf-8') as n:\n",
    "                n.write(f + '\\n')\n",
    "                n.close()\n",
    "    print('Обработка mystem файлов из директории plain в формате plain text завершена.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ф-я, обрабатывающая все файлы директории plain в mystem в формате xml\n",
    "\n",
    "def mystem_xml():\n",
    "    path_base = os.path.join('.', 'Yoshkar-Ola\\\\plain')\n",
    "    files = list_files(path_base)\n",
    "    for f in files:\n",
    "        try:\n",
    "            f_path_new_txt = f.replace('plain', 'mystem-xml')\n",
    "            f_path_new_xml = f_path_new_txt.replace('txt', 'xml')\n",
    "            if not os.path.exists(f_path_new_xml):\n",
    "                mystem_path = os.path.join('.', 'mystem.exe')\n",
    "                os.system(mystem_path + \" -cid --format xml \" + f + ' ' + f_path_new_xml)\n",
    "                cut_meta(f_path_new_xml)\n",
    "        except FileNotFoundError:\n",
    "            print('Ошибка при обработке файла ' + f)\n",
    "# эти файлы уже не добавляем в файл с ошибками mystem, потому что в обеих функциях mystem ругается на одни и те же файлы\n",
    "    print('Обработка mystem файлов из директории plain в формате xml завершена.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# т.к. несколько файлов все равно может улететь в ошибку после mystem, и я не знаю, что с ними делать - вроде все норм - удалим их,\n",
    "# чтобы во всех директориях было равное количество файлов. Для этого воспользуемся созданным файлом с названиями файлов-ошибок\n",
    "\n",
    "def delete_error_files():\n",
    "    with open(os.path.join('.', 'Yoshkar-Ola\\\\errors_mystem.txt'), 'r', encoding='utf-8') as f:\n",
    "        errors = f.read()\n",
    "        errors_l = errors.split('\\n') # считываем файл с ошибками, отсекая перенос на другую строку! (я просто рассплитила по переносам)\n",
    "    for error in errors_l: \n",
    "        if os.path.exists(os.path.join(error)): # как минимум первая строка - шапка \"Ошибки были в следующих файлах...\"\n",
    "            os.remove(os.path.join(error))\n",
    "            print('Файл ' + error + ' удален.')\n",
    "    print('Файлы, на которых mystem ломается, удалены.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# На всякий случай считаем слова\n",
    "\n",
    "def count_words(directory):\n",
    "    files = list_files(directory)\n",
    "    words = 0\n",
    "    for f in files:\n",
    "        with open(f, 'r', encoding = 'utf-8') as k:\n",
    "            text = k.readlines()\n",
    "            text_wm = text[6:] # считаем без метаданных в шапке файла\n",
    "            text_wm_str = ''.join(text_wm)\n",
    "            text_l = text_wm_str.split()\n",
    "            words += len(text_l)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Т.к. папки создавались в большом количестве, но многие остались пустыми (напр., за декабрь 2017), удаляем пустые папки\n",
    "# Пустых папок много, т.к. сайт газеты новый, и там есть статьи только начиная с конца 2016 года + 1 статья за 2014\n",
    "\n",
    "def delete_empty_dirs(directory):\n",
    "    for d in os.listdir(directory): # берем все папки директории\n",
    "        a = os.path.join(directory, d) # пишем их адрес\n",
    "        if os.path.isdir(a): # делаем то же с новыми папками \n",
    "            delete_empty_dirs(a) # рекурсия - пока не дойдем до дна:)\n",
    "            if not os.listdir(a):\n",
    "                os.rmdir(a)\n",
    "                print('Директория ' + a + ' удалена')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    make_folders()\n",
    "    csv_meta_base()\n",
    "    plain()\n",
    "    directory = os.path.join('.', 'Yoshkar-Ola')\n",
    "    directory1 = os.path.join(directory, 'plain')\n",
    "    rename_file(directory1)\n",
    "    mystem_plain()\n",
    "    mystem_xml()\n",
    "    delete_error_files()\n",
    "    os.remove(os.path.join('.', 'Yoshkar-Ola\\\\errors_mystem.txt'))\n",
    "    delete_empty_dirs(directory)\n",
    "    print('Все пустые директории удалены.')\n",
    "    print('Количество слов в корпусе ' + str(count_words(directory1)))\n",
    "    print('Готово.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
